{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API keys\n",
    "api_springer = \"\" #full text for open-access articles in XML format (api.springernature.com/openaccess/jats/doi/[DOI]?api_key=[API])\n",
    "api_elsevier = \"\" #full text for any article I have access to in XML format (https://api.elsevier.com/content/article/doi/[DOI]?APIKey=[API]?view=FULL)\n",
    "api_wiley = \"\" #full text, but PDF download only.\n",
    "api_gpt = \"\"\n",
    "#BioC API: offers PMC OA and Author Manuscript Collection in XML format via PubMed ID or PMC ID (https://www.ncbi.nlm.nih.gov/research/bionlp/RESTful/pmcoa.cgi/BioC_[format]/[ID]/[encoding])\n",
    "api_semanticscholar = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcid_balskus = \"https://orcid.org/0000-0001-5985-5714\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the future, I can filter using multiple ORCIDs by using the '|' operator. (Up to 50 values)\n",
    "\n",
    "def build_author_works_url(orcid):\n",
    "    # specify endpoint\n",
    "    endpoint = 'works'\n",
    "\n",
    "    # build the 'filter' parameter\n",
    "    filters = (\n",
    "      f'author.orcid:{orcid}',\n",
    "      'type:article', #excludes book-chapter, dissertation, book, dataset, paratext, other, reference-entry, report, peer-review, standard, editorial, erratum, grant, letter\n",
    "      'is_paratext:false' #excludes paratext\n",
    "    )\n",
    "\n",
    "    # put the URL together\n",
    "    return f'https://api.openalex.org/{endpoint}?filter={\",\".join(filters)}&mailto=kl4898@stern.nyu.edu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publications(orcid):\n",
    "    # get the URL\n",
    "    url_with_cursor = build_author_works_url(orcid) + \"&cursor={}\"\n",
    "\n",
    "    # initialize\n",
    "    cursor = '*'\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    while cursor:\n",
    "        url = url_with_cursor.format(cursor)\n",
    "        response = requests.get(url).json()\n",
    "        data = pd.DataFrame(response['results'])\n",
    "        df = pd.concat([df, data])\n",
    "        cursor = response['meta']['next_cursor']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus = get_publications(orcid_balskus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_location_name(item):\n",
    "    try:\n",
    "        return item['source']['display_name']\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_location_publisher(item):\n",
    "    try:\n",
    "        return item['source']['host_organization_lineage_names'][-1]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus['journal'] = balskus.primary_location.apply(get_primary_location_name)\n",
    "balskus['publisher'] = balskus.primary_location.apply(get_primary_location_publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus[balskus['publisher']=='Wiley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  response_format={\"type\":\"json_object\"},\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are supposed to pretend to not understand anything the user says.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Springer API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://api.springernature.com/metadata/pam/doi/10.1007/s11276-008-0131-4?api_key=yourKeyHere\n",
    "\n",
    "http://api.springernature.com/openaccess/jats/doi/10.1038/s41586-019-0894-z?api_key=c1ca0f1fd4a20828a0b701cbc86d486a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://api.springernature.com/openaccess/jats/doi/10.1038/s41586-022-04444-3?api_key=c1ca0f1fd4a20828a0b701cbc86d486a\"\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth(element):\n",
    "    depth = 0\n",
    "    while element.getparent() is not None:\n",
    "        depth += 1\n",
    "        element = element.getparent()\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = etree.fromstring(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = list(root.iter('sec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sec in enumerate(secs):\n",
    "    depth = get_depth(sec)\n",
    "    print(f\"Section {i+1}: Depth = {depth}, Text = {sec.text}, Attributes = {sec.attrib}\")\n",
    "    concatenated_text = sec.text or ''\n",
    "    \n",
    "    for child in sec.iterdescendants():\n",
    "            concatenated_text += child.text or ''\n",
    "            concatenated_text += child.tail or ''\n",
    "            concatenated_text += ' '\n",
    "\n",
    "    print(f\"Concatenated Text up to next title of same depth: {concatenated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus.publisher.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balskus.journal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussion = titles[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = titles[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sibling = methods.getnext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = get_depth(methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sibling = discussion.getnext()\n",
    "while True:\n",
    "    print(sibling, sibling.tag, get_depth(sibling), sibling.text)\n",
    "    sibling = sibling.getnext()\n",
    "    if sibling is None:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods.getnext().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"nchembio.1890.pdf\")\n",
    "out = open(\"nchembio.1890.txt\", \"wb\")\n",
    "for page in doc:\n",
    "    text = page.get_text().encode(\"utf8\")\n",
    "    out.write(text)\n",
    "    out.write(bytes((12,)))  # form feed character\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the URL and the headers\n",
    "url = 'https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1111/1467-923X.12168'\n",
    "headers = {'Wiley-TDM-Client-Token': api_wiley}\n",
    "\n",
    "# Send the GET request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Write the response headers to a file\n",
    "    with open('12168-headers.txt', 'w') as file:\n",
    "        for key, value in response.headers.items():\n",
    "            file.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    # Write the response content to a PDF file\n",
    "    with open('12168.pdf', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the data: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the URL and the headers\n",
    "url = 'https://api.semanticscholar.org/datasets/v1/release/2024-01-02/'\n",
    "headers = {'x-api-key': api_semanticscholar}\n",
    "\n",
    "# Send the GET request\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
