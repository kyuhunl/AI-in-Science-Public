METHODS


Model

Suppose we are interested in segmenting a new brain image, hereinafter referred to as the target image. We have available R previously manually segmented images to use as atlases after aligning the labeled brains to the target. This alignment is done via image registration, the process of transforming one image to the space of another via an affine or nonlinear map.

The registration problem is itself an ongoing area of research in the imaging literature, but state of the art tools include the FLIRT and FNIRT functions in FSL (Jenkinson and Smith, 2001;Jenkinson et al., 2002;Greve and Fischl, 2009;Jenkinson et al., 2012), DRAMMS (Ou et al., 2011), LDDMM (e.g., Zhong et al., 2010), and SyN registration (Tustison and Avants, 2013). In what follows, we assume that a single algorithm is used to register each atlas to the target, but our proposed framework can easily account for different registration algorithms.

In either case, the sources of uncertainty leading to corruption of the atlas labels are the radiologists' imperfect manual segmentations, the set of brains that have been manually segmented, none of which is identical to the target brain, and the registration algorithm itself, which cannot produce a perfect alignment between images.

After registering each atlas to the target, we have R images indexed by v = 1, . . . , V , where V is the number of voxels. Corresponding to atlas r ∈ {1, . . . , R} is a set of labels {Y 1r , . . . , Y V r } ∈ {0, 1} V . The atlases will disagree with each other after registration and will each be a corrupted version of the underlying truth. In addition to the observed labels Y vr , let T v ∈ {0, 1}, v = 1, . . . , V , denote the "true" (unobservable) status of the voxel v, so that T v = 1 indicates that voxel v is a part of the structure of interest, and T v = 0 otherwise.

We associate to each atlas r a sensitivity ξ, an ability to correctly detect when a voxel is truly part of the structure of interest. Similarly, we have also for each atlas a specificity ψ, an ability to correctly determine when a voxel is truly outside of the ROI. Since the quality of any registration can vary throughout an image, the best atlas to use depends on location (Artaechevarria et al., 2009). Thus, we allow the sensitivity and specificity of each atlas to be a function not only of the specific atlas, but also the voxel. We suppose that
P (Y vr = 1 | T v = 1) = ξ(v, r) and P (Y vr = 0 | T v = 0) = ψ(v, r)
, for atlases r = 1, . . . , R and voxels v = 1, . . . , V . Given the true voxel statuses and the sensitivity and specificity of each atlas, we assume that observed labels are conditionally independent,
Y vr | T v , ξ(v, r), ψ(v, r) ind. ∼ Bern(p * (v, r)), v = 1, . . . , V ; r = 1, . . . R,(1)
where p * (v, r) = ξ(v, r) Tv [1 − ψ(v, r)] 1−Tv . For example, if Y vr 0 and Y v r 0 come from the same atlas r 0 , we assume the dependence between them is only due to the dependence between ξ(v, r 0 ) and ξ(v , r 0 ) and between ψ(v, r 0 ) and ψ(v , r 0 ).

We propose a framework for incorporating spatial smoothness into the sensitivity and specificity processes, as well as additional covariate information that can be informative with respect to the true voxel status T v . The spatial process and covariate models themselves depend on unobservable and unknown parameters. Hence we take a hierarchical Bayesian approach and assign them prior distributions as well. The prior distributions and concomitant hyper-parameters are described in this subsection.

It is important to impose smoothness on the reliabilities to mitigate the effect of image noise (Artaechevarria et al., 2009). We model the sensitivities and specificities as ξ(v, r) = Φ(x vr β r + φ vr ); ψ(v, r) = Φ(z vr γ r + η vr ),

where Φ(·) is the standard Gaussian CDF, x vr ∈ R and z vr ∈ R k are known vectors of covariates with coefficients β r and γ r , respectively, and φ vr and η vr are elements of meanzero Gaussian Markov random fields (GMRFs; Rue and Held, 2005). Our experience is that it is often sufficient to simply set x = z = 0 to let the spatial processes detect the trends a posteriori. Observe that we assume that ξ(v, r) and ψ(v, r) are independent of each other, since they are defined by two mutually exclusive outcomes, T v = 1 and T v = 0.

We assume φ r = (φ 1r , ..., φ V r ) ∈ R V and η r = (η 1r , ..., η V r ) ∈ R V , r = 1, ..., R, each independently follow conditionally autoregressive models (CAR; Besag, 1974), given by
φ r ind. ∼ N V 0, τ −1 φ r (D − ρ φ r W ) −1 ; η r ind. ∼ N V 0, τ −1 η r (D − ρ η r W ) −1 .(3)
Here
, W = {w ij } V i,j=1 ∈ R V ×V is a neighborhood matrix such that w v,v = I(v ∼ v ),
where v ∼ v if and only if voxels v and v share an edge or a corner, I(·) is the indicator function,
and D = diag V j=1 w ij , i = 1, . . . , V ∈ R V ×V .
This yields a nonstationary process due to the edge effects; i.e., the voxels on the edges have different numbers of neighbors than the interior voxels, leading to different marginal variances. Besag and Kooperberg (1995) observe that when images are of large dimension and the regions of interest are in the interior, edge effects are negligible with respect to inferences, so one can safely ignore them.

When T v = 0 for all v, ξ(v, r) does not appear in the likelihood determined by (1) and hence φ r is not updated in the posterior. Since T 1 = · · · = T V = 0 with positive probability, the prior distribution on φ r must be proper to avoid an improper posterior, and likewise for η r . Thus, we include the "propriety parameters" ρ φ r and ρ η r in (3) to force the precision matrices to be nonsingular, as suggested by Banerjee et al. (2015). A sufficient condition is |ρ φ r | < 1, in which case (D − ρ φ r W ) is diagonally dominant and hence positive definite.

It is likely that we will have available auxiliary information concerning the true location of the structure of interest. Toward this end, we suppose that, where c v ∈ R J is a vector of covariates pertaining to voxel v, δ is the corresponding vector of regression coefficients, and g : (0, 1) → R is a one-to-one and differentiable link function. We assume any dependence between inclusion indicators is completely explained by the covariate
P (T v = 1 | δ) = g −1 (c v δ), v = 1, . . . , V,(4)information; i.e., T v ⊥ T v | δ, v = v .
In Sections 3 and 4, we demonstrate the use of signed distance label maps and either normalized image intensity or tissue class segmentations as covariate information for c v . In Subsection 2.2, we discuss prior elicitation for δ.

The model is completed with prior distributions on the regression coefficients and precision parameters in (2), (3), and (4). We take conventional Gaussian and Gamma priors for these parameters, since they are sufficiently flexible with appropriate specification of the corresponding hyperparameters. Thus, we assume
β r iid ∼ N (0, Σ β ) ; γ r iid ∼ N k (0, Σ γ ) , r = 1, . . . , R δ∼N J (0, Σ δ ) , τ φ r iid ∼ Ga (a φ , b φ ) ; τ η r iid ∼ Ga (a η , b η ) , r = 1, . . . , R.(5)
To aid with exposition, Figure 1 provides a graphical depiction of our proposed model. 
Y = (Y 11 , . . . , Y V R ) ∈ R V R , is π(T , ω | Y ) ∝ V v=1 R r=1 Φ(φ vr ) YvrTv {1 − Φ(φ vr )} (1−Yvr)Tv Φ(η vr ) (1−Yvr)(1−Tv) {1 − Φ(η vr )} Yvr(1−Tv) × V v=1 {g −1 (c v δ)} Tv {1 − g −1 (c v δ)} 1−Tv N J (δ|0, Σ δ ) × R r=1 N V (φ r |X r β r , τ φ r (D − ρ φ r W ) −1 )N V (η r |Z r γ r , τ η r (D − ρ η r W ) −1 ) × R r=1 N (β r |0, Σ β )N k (γ r |0, Σ γ )Ga(τ η r |a η r , b η r )Ga(τ φ r |a φ r , b φ r ).
We remark that our proposed label fusion approach, particularly its ability to incorporate atlas-independent information about structure location, is considerably different from popular voting-based approaches. Each of the additional approaches we consider in Section 4 estimates the probability of inclusion of voxel v withP (
T v = 1|Y) ∝ R r=1 w r (v)Y vr , where w r (v)
is a weight assigned to the rater r classification at voxel v. Simple majority voting gives each atlas equal weight throughout the image (w r (v) ≡ 1), globally-weighted majority voting takes w r (v) ≡ w r , and both locally-weighted majority voting and JLF produce weights that depend on both the rater (r) and voxel (v). What the weighted approaches have in common is that weights are determined via some measure of image similarity that serves as a proxy for image registration quality and thus how "trustworthy" a particular atlas is. Put another way, each of the voting procedures and JLF are discriminative models for classification in that they aim to estimate P (T v |Y ) directly without accounting for any underlying process in P (Y vr |T v ). By contrast, our proposed approach is a generative approach that includes both pieces by classifying based on a model of the form P (Y vr ,
T v ) = P (Y vr |T v )π(T v ).
The gray matter information is included as part of the prior information contained in π(T v ) via a logit regression. A prior π(T v ) is not part of any of the other procedures, and so there is no place in which we can directly incorporate gray matter or other potentially informative information derived from the target image without substantially expanding their assumed models. Both discriminative and generative classification models have their strengths and weaknesses (Ng and Jordan, 2002). In Section 4, we use an independent gray matter segmentation to guide segmentation, but other information could be used in different settings.


Prior Specification

To specify the hyperparameters determining the prior distributions for β r , γ r , φ r , and η r appearing in (2), we recognize that Φ(4) − Φ(−4) ≈ 1, so that the effect of the mean function on the likely values of the reliability parameters is almost certainly between −4 and 4. For instance, considering the sensitivity, a priori we suppose that for any v and any r, P (|x vr β r + φ vr | ≤ 4) ≈ 1 for all x vr . With a pure spatial process (x vr = 0, for all v, r), this requirement becomes P (|φ vr | ≤ 4) ≈ 1. To use this to induce a prior on the spatial effect (Bernardinelli et al., 1995;Eberly and Carlin, 2000). With eight neighbors at a voxel v, for instance, the desired constraint can be solved to yield τ φ r ≈ 0.5. Hence we take a φ = 1 and b φ = 2 in (5). The argument is the same for specifying the hyperparameters on γ r and τ η r .
φ vr , we use the fact that V ar(φ vr ) ≈ (0.7 2 w v .τ φ r ) −1 , where w v . = V k=1 w vk
With prior knowledge concerning the underlying structure of interest, it is possible to induce a prior on δ through a so-called conditional mean prior (CMP; Bedrick et al., 1996). Under this approach, we partition the J-dimensional covariate space into J regions and choose hypothetical covariate vectors c 1 , c 2 , . . . , c J so that C = ( c 1 c 2 . . . c J ) ∈ R J×J is nonsingular. A prior is put on the mean response at these covariate values, E[( T 1 , . . . , T J ) | δ] = G ( Cδ) ∈ R J , where G (·) applies g −1 componentwise. While the regression coefficients may be difficult to interpret, we can meaningfully assign a distribution to p j = g −1 ( c j δ) = P ( T j = 1 | δ) using a Beta distribution with shape parameters chosen to reflect the prior knowledge at the covariate values. Bedrick et al. (1996) 
show that if p j indep. ∼ Beta(a p j , b p j ), j = 1, . . . , J, then the induced prior is π(δ) ∝ J j=1 {g −1 ( c j δ)} a p j −1 {1 − g −1 ( c j δ)} b p j −1ġ −1 ( c j δ)
. Posterior inference is facilitated via MCMC, taking advantage of data augmentation (Albert and Chib, 1993) and so-called chromatic sampling (Brown et al., 2021) for updating the spatial fields. A more detailed discussion may be found in the Supplementary Material. Notice that each atlas segmentation is slightly offset from the truth in a different direction.


NUMERICAL STUDIES

To demonstrate the utility of incorporating auxiliary information into the label fusion procedure, we consider two controlled scenarios in which we can compare results against a known truth. First, we consider the ideal case in which each of the atlas segmentations is reliable and closely corresponds to the true structure. Covariate information is not critical in this situation, as any of the considered procedures perform well. To illustrate the benefit of including concomitant information to guide segmentation, we study in the second subsection a challenging situation in which some of the segmentations are unreliable but nevertheless tend to agree on the wrong location. This situation is similar to what can occur when healthy brain images are used as atlases for segmenting diseased brains; i.e., they might all systematically oversegment the hippocampus since healthy hippocampi tend to be larger than those that are diseased.


The Case of Quality Atlases

Here we are interested in recovering a target structure in a two-dimensional image using R = 4 atlases. We simulate a 40 × 40 grid, displayed in Figure 2. Suppose that each of the atlas segmentations perform well, each being only slightly offset from the truth. The atlases are also displayed in Figure 2.

To compare results of our procedure with and without covariates, we find the signed distance label (SDL) transforms for each atlas (Iglesias et al., 2012). An SDL transform for a binary image assigns to each pixel a number corresponding to its distance from the nearest edge in an image, where an edge is indicated by a zero adjacent to a one. The sign of the distance corresponds to whether or not the pixel is inside or outside an identified structure; e.g., a pixel has negative distance if it is inside the structure, positive distance if it is outside, and zero if it is on the boundary. We consider the sum of the signed distance label transform maps as a possible covariate. In this case, the dimension of the predictor space with and without the covariate included is J = 2 and J = 1, respectively. In the former case, our CMP prior is induced by supposing a priori that a voxel with a large negative signed distance label has probability 0.9 of being in the structure, and probability 0.10 if its signed distance label is large positive. With no predictors at all, we induce the prior on δ by supposing there is a 50% chance that a borderline voxel (signed distance label = 0) is truly part of the structure. Further discussion of prior elicitation for the numerical experiments, as well as MCMC implementation, is in the online Supplementary Material. Figure 3 displays the posterior probability maps obtained from including the signed distance labels as covariates as well as the results from using an intercept-only model. We observe a more clearly-defined region of high and low probability when the covariate information is included, whereas using no covariate information results in a less clearly defined region. The latter is a byproduct of the fact than an intercept-only Bayesian probit regression is equivalent to allowing every pixel equal prior probability of inclusion in the structure, so that the atlases alone determine the likely region(s) of interest.


Using Auxiliary Information

It may occur in practice that multiple reference atlases are subject to the same deleterious effect, resulting in multiple atlases closely agreeing on an incorrect segmentation. If we have one atlas that registered well and provides a good segmentation, it could still be outweighed by multiple poor atlases. Thus any voting procedure would produce a poor segmentation. We again simulate a structure on a 40 × 40 grid, displayed in Figure 4. Also displayed in the figure is one reliable candidate segmentation and three poor segmentations, the latter of which closely agree. We also simulate image intensities as might be obtained from an additional imaging modality. Voxelwise image intensity similarity is often used to quantify rater reliability throughout an image (Isgum et al., 2009). As such, we simulate image intensity similarities for each atlas, displayed in Supplementary Figure 1. To make the assessment more realistic, we slightly offset the intensity differences from the areas of poor segmentations.

We again find the SDL transform for each atlas (Iglesias et al., 2012). Here, we take a weighted sum over the atlas-specific SDL maps, where the weights are inversely proportional to the square of the intensity difference between the rater image and the target; i.e.,
c v1 = 4 r=1 |i r (v) − i t (v)| −2 d r (v)/( 4 r=1 |i r (v) − i t (v)| −2 )
, where i r (v) and i t (v) are the intensity values for rater image r and the target image at pixel v, respectively, and d r (v) is the SDL assigned to pixel v from rater image r. We use the pixel-level intensities as additional covariates, c v2 = i t (v). It is important to include a distance-intensity interaction, c v3 := c v1 c v2 , since high intensity voxels far away from the object of interest should not be included, but the information can be helpful when we believe a voxel is close to the object.

We use CMP to induce a prior on the δ coefficients in (4). The dimension of the predictor space is J = 4, so we augment the model with pseudo-observations under covariate values corresponding to (i) small distance, high intensity; (ii) large distance, low intensity; (iii) mid-distance and average intensity; and (iv) large distance but high intensity. We impose prior knowledge that (i) is very likely to be included in the object, (ii) is very unlikely to be included, (iii) is a borderline case, and (iv) is not very likely to be included. See the Supplementary Material for more details.

For posterior inference, a single Monte Carlo Markov chain is run for 100,000 iterations, thinning to every 25 th iterate to save memory and reduce autocorrelation. The first half of the chain is discarded as a burn-in period. We use trace plots of the δ coefficients along with Geweke statistics (Geweke, 1992) 
P (T v = 1 | Y ) = N −1 N k=1P (T v = 1 | ω (k) , Y ),
where ω (k) denotes the k th MCMC iterate of all the parameters except T 1 , . . . , T V . Close agreement between the target and the estimate is evident. As expected, the uncertainty about the structure is largest near the 
D := 2 V v=1 d v T v /(2 V v=1 d v T v + V v=1 d v (1 − T v ) + V v=1 (1 − d v )T v )
, is often used as a measure of image similarity (though it may not be the best measure when the structure of interest is small relative to the image size (Taha and Hanbury, 2015)). Dice values close to one indicate strong agreement between two images. Despite the fact that all of the poor segmentations were downweighted relative to the good one, they still outweigh the quality atlas in each voting procedure, resulting in poor segmentation. Thresholding the posterior probability map has resulted in 110% improvement in similarity over even the most favorable version of majority voting.

Often, a researcher is uninterested in a binary segmentation for its own sake, but rather as a means to an end; e.g., volume estimation. With a binary segmentation, the only way to estimate the volume is by summing the binary indicators over the image. In contrast, our approach facilitates construction of a distribution of plausible volumes. Let T 
N −1 N k=1 V v=1 T (k) v ≈ V v=1 E(T v | Y ) = V v=1 E[P (T v = 1 | ω, Y )]
, we estimate the structure volume on iteration k with M (k) := V v=1 P (T v = 1 | ω (k) , Y ), k = 1, . . . , N . The right panel in Figure 6 displays the estimated marginal distribution of volume, along with the true volume and the volume estimates obtained from the three voting procedures. The true volume is well within the high probability region of the distribution. We have no way of formally quantifying the uncertainty associated with the voting estimates.

These simulation results demonstrate possible improvements over simple and weighted majority voting through our proposed Bayesian label fusion model. This is possible even when strongly corrupted atlases are used as inputs to the label fusion, since covariate and prior information can protect against otherwise poor segmentaitons. By allowing each atlas' reliability to vary throughout an image, we account for the fact that no atlas is uniformly more reliable than another throughout the image. Even in the case of quality atlases (e.g., when healthy brains are used to segment healthy brains with a good registration algorithm), we see that including a covariate can improve the segmentation versus no predictors at all.


APPLICATION TO HIPPOCAMPUS SEGMENTATION

The Alzheimer's Disease Neuroimaging Initiative (ADNI; http://www.adni.loni.usc.edu) is a multi-center, longitudinal study with the goals of better understanding Alzheimer's disease (AD) and developing effective biomarkers. The data are publicly available via applying for access, subject to approval by the ADNI Data and Publications Committee. Using demographic information available from the ADNI, we created an age-and sex-matched, casecontrol sample of six AD and six healthy control subjects. Manual segmentations of the left and right hippocampus were obtained for each subject from the Harmonized Protocol For Hippocampal Volumetry (Boccardi et al., 2015). The corresponding T 1 images were downloaded from the LONI IDA website. For each image, we applied N4 inhomogeneity correction (Tustison et al., 2010) and Multi-atlas Skull Stripping (Doshi et al., 2013). For each target T 1 image we consider, the remaining T 1 atlases were non-linearly registered to the target image using SyN deformable registration with mutual information cost and Welch windowed sinc interpolation (Avants et al., 2011a) in R. The concomitant transformations were applied to each manual segmentation with nearest-neighbor interpolation to obtain the atlases for each target. The T 1 intensity values were normalized across images using white stripe (Shinohara et al., 2014).

We focus on using known control subjects' brain images as atlases for segmenting the brain of an individual that has been diagnosed with AD. The heterogeneity between the structure of the diseased brain and the healthy controls makes the segmentation task more challenging than in the conventional case. We demonstrate the utility of tissue class information in addition to atlas-target image agreement. After considering the single-brain case, we summarize the performance of our proposed approach over all six AD brain images.


Segmenting the Hippocampus of a Single Diseased Brain

We take as our target the three-dimensional brain image of a 78 year old male diagnosed with AD. The six controls are registered to the target brain. To reduce the size for the sake of computation without losing information about the plausible location and volume of the hippocampus of interest, the images are cut to three-dimensional rectangles of the same size, where the rectangle is the smallest box containing the largest segmentation. This results in each image having dimension 70 × 39 × 27 so that V = 73, 710 and R = 6 in (1).

One representative slice from each of the resulting three-dimensional atlas segmentations is displayed in Figure 7, along with the same slice from each of the manual segmentations.

In this figure we observe a systematic tendency for each atlas to considerably over-segment the hippocampus when compared to the manual segmentation. This is due in part to the fact that each atlas is based on a brain that has not been diagnosed with AD. It is well established that hippocampal atrophy is more severe in AD patients compared to a healthy population. Thus, the hippocampi from the reference brains tend to be larger than than that in the target image; a systematic discrepancy that persists even after registering the labels to target image space. These discrepancies between the atlases and the target create challenges for label fusion approaches.

For covariate information, we take the weighted sum of the SDL maps for each atlas (rescaled to the unit interval), where each atlas is weighted voxelwise by its T 1 intensity similarity with the target T 1 image. The use of atlas-target image agreement is common Figure 7: Axial view of one slice of the manually segmented hippocampus (top) and six atlas segmentations (bottom two rows) for the label fusion example. The target brain has been diagnosed with AD; the atlases come from healthy controls. among modern label fusion algorithms and has proven to be useful, so we use it here. To further guide the segmentation, however, we recognize that the hippocampus is a structure consisting only of gray matter. Thus we use a pre-computed tissue class segmentation to compute voxelwise gray matter indicators for inclusion in our regression model. The tissue class segmentation is obtained via the ATROPOS algorithm (Avants et al., 2011b). The SDL map and tissue class segmentation, along with the manually-segmented target image, are displayed in Supplementary Figure 4. We include an interaction term to downweight the effect of the presence of gray matter when a voxel is thought to be far away from the hippocampus.

To elicit the prior on the regression coefficients via CMP, we use pseudodata to impose our prior knowledge that (i) gray matter and a small SDL has a very high likelihood of truly belonging to the hippocampus, (ii) a large SDL and not gray matter is very likely to be external to the hippocampus, (iii) gray matter with a large SDL is somewhat likely external to the hippocampus, and (iv) a small SDL but segmented as not belonging to gray matter has a marginal probability of being part of the hippocampus, due to possibly misclassified  There is considerable uncertainty about the edges. If a researcher were only interested in the hippocampal volume for the patient, these probabilities could be used directly to estimate the volume, as discussed below.

One can threshold the posterior probabilities to obtain a binary inclusion map. After thresholding, we compare the resulting segmentation to those obtained by simple majority voting, globally-weighted majority voting, locally-weighted majority voting, and JLF. The global weighting is inversely proportional to each atlas' average T 1 intensity difference from the target. Local weighting is done similarly using voxel-specific intensity differences. Figure   9 displays one slice of the manual segmentation along with that which is obtained by thresholding the posterior inclusion probabilities at 0.5. The hippocampus is a relatively small structure compared to the full three-dimensional image (as can be seen in, e.g., Supplementary Figure 4). In this case, Taha and Hanbury (2015) argue that the Dice coefficient defined in Section 3 is not the best measure for evaluating a segmentation. However, the volume of the hippocampus is important for volumetry in the study of AD progression. Thus, we follow the suggestion of Taha and Hanbury (2015) and use the volume similarity as an evaluative metric, defined as V S = 1 − |F N − F P |/(2T P + F P + F N ), where F N, F P, and T P denote false negatives, false positives, and true positives, respectively. Bayesian label fusion attains V S = 0.989. This is competitive with JLF, the current state-of-the-art (V S = 0.997), and superior to both simple and weighted voting procedures. (VS values are displayed in Figure   9.) Unlike the other automatic segmentations, the fully Bayesian label fusion produces measures of uncertainty in the form of a posterior probability distribution that can be used to derive marginal distributions of any quantity of interest, as we discuss below. Further, our proposed model also has the ability to estimate the spatially-varying reliability parameters for each atlas. Supplementary Figure 6 displays the sensitivity and specificity maps for one selected atlas. We see smooth decay of sensitivity between regions of high agreement and low agreement with the manual segmentations. Since the sensitivity is conditional on the voxel truly being part of the structure (T v = 1), the model is only capable of estimating sensitivity in areas where it estimates a high probability of the voxel truly being part of the structure.

The fields return to their prior means as they move away from the structure estimate. Similarly, the specificity values are estimated to be very high away from the targeted structure, where all atlases agree on the voxels being excluded. As already mentioned, only healthy brains are used as atlases. The systematic differences are not completely captured by atlas-target image dissimilarities. Despite accounting for image dissimilarity, there is a tendency for the established methods to over-segment the hippocampus. The Bayesian label fusion model facilitates explicit incorporation of the estimated gray matter pattern as a predictor. Our prior specification allows for the possibility that the tissue classes are incorrectly assigned in some places, but are mostly reliable. The effect of the gray matter segmentation as auxiliary information can be clearly seen by comparing it even with our own model in which this information is ignored but the model is otherwise identical. Figure 10 displays the posterior inclusion probabilities obtained without using the gray matter information, along with the results already presented for reference.

Using only the intensity-similarity-weighted distance labels yields a Bayesian regression analogue to the other approaches that only weight by intensity similarity. The additional tissue class information is able to prevent oversegmentation of the diseased structure.

In practice, an anatomical structure is segmented to obtain important information such and without (right) using a gray matter tissue class segmentation as a covariate in the Bayesian label fusion model. Note that each image displays only the subset of the full brain image that was used for the label fusion -the smallest rectangle containing the largest segmentation. The coronal view displays no structure since the slice shown is in between the left and right hippocampus.

as its volume or average image intensity within the structure. In our case, segmenting the hippocampus is a step toward estimating its volume. If we only obtain a binary map, then the only way to estimate the volume is by summing the indicators. Doing so ignores many sources of uncertainty, including image pre-processing, registration error, biological variation, and rater variability. Monte Carlo sampling also facilitates estimation of a distribution of plausible volumes throughM (k) , defined in Section 3. Figure 11 displays the marginal volume densities for the diseased brain of interest, both with and without gray matter included in the Bayesian label fusion model. Vertical lines indicate the manually-segmented volume and the volume estimates from the other procedures considered. The benefit of including the gray matter information is again evident with the improved agreement of the volume distribution with the manual segmentation. In this case, though, we see that even without the gray matter information the Bayesian model outperforms the three majority voting procedures.


Aggregated Results

Here we present the results of using the control brain images as atlases for each of the six AD patients in our dataset. Figure 12 summarizes the volume estimates and volume similarities between the automatic and manual segmentations. In terms of volume similarity, our approach and JLF separate themselves from the three voting approaches. In addition to being competitive with the current state of the art, our approach is the only one that meaningfully produces measures of associated uncertainty, depicted in this case as 99% posterior credible intervals. This uncertainty is particularly evident in the second subject from the top depicted in the left panel of Figure 12. The point estimate (posterior mean) is quite far from the manually segmented volume relative to differences in the other brain images.

However, the posterior distribution indicates a large amount of uncertainty about this particular estimate. Indeed, the MCMC trace plot of volume estimates for this subject (labeled 1263), displayed in Supplementary Figure 6, suggest that the marginal posterior distribution of volume is bi-modal. This is a feature of the posterior distribution that an optimization routine would likely miss. Lastly, we remark that even a trained expert will produce slightly different manual segmentations of the brain on two different occasions, so there is uncertainty associated with each manual segmentation itself. This is not quantified here. Thus it is impossible to assess any 'significant' difference between volume estimates from our proposed approach and a manually estimated volume.

These results demonstrate the feasibility of our approach on a full three-dimensional segmentation as well as additional useful information that would be unavailable otherwise.

Posterior probability maps can be used to summarize where the hippocampus is likely to be. A simple thresholding rule yields image similarities that are competitive with the stateof-the-art when using healthy brains as atlases for diseased cases. However, thresholding is unnecessary when the goal is to estimate the volume of the hippocampus, as shown by the availability of a posterior volume distribution. Incorporating tissue class information into a generative Bayesian model for segmentation results in more faithful estimates of the hippocampal volume along with meaningful measures of uncertainty.