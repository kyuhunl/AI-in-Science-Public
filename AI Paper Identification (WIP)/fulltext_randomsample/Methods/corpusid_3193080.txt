METHODS


Functional similarity graph

The central idea of IsoRankN is to build a multiple network alignment by local partitioning of the graph of pairwise functional similarity scores.


Box 1. The Original IsoRank Algorithm.

IsoRank works on the principle that if two nodes of different networks are aligned, then their neighbors should be aligned as well. In lieu of sequence similarity information, the functional similarity score R ij between vertex v i and v j is the set of positive scores which satisfies:
R ij = v u ∈N(v i ) v w ∈N(v j ) 1 |N(v u )||N(v w )| R uw , where N(v i ) is the neighborhood of v i within its own network.
This can also be viewed as the steady-state distribution of a random walk on the direct product of the two networks.

To integrate a vector of sequence homologies, E, IsoRank takes a parameterized average between the network-topological similarity and the known sequence homology. It uses the power method to find the unique positive R satisfying
R = αAR+(1−α)E, with 0 ≤ α ≤ 1, where A ij,uw = 1 |N(v u )||N(v w )| , v u ∈ N(v i ),v w ∈ N(v j ), 0, otherwise.
Given the resulting vector of pairwise functional similarity scores, R, a discrete network alignment is then greedily generated.

Specifically, given k PPI networks, G 1 ,G 2 ,...,G k , we first compute the functional similarity scores of every pair of cross-species proteins
(v i ,v j ) ∈ (G l ,G m )
. This is done using the original IsoRank algorithm (Box 1), but without the final step of greedily selecting an alignment. The scores generated by IsoRank have the advantage of being highly noise tolerant, a result of using a spectral approach. The result is a functional similarity graph, a weighted complete k-partite graph on the k sets of proteins, where each edge is weighted by its functional similarity score. If the PPI networks were complete and exact, the multiple alignment problem would simply be to find maximally weighted cliques. As the networks are not, we introduce the star spread method to find highly similar near cliques, which yields a multiple alignment. In addition, in contrast to the seed-path extension method used by NetworkBLAST-M, our method is similar to the star aligned approach in multiple sequence alignment introduced by Lipman et al. (1989) and CLUSTAL W (Thompson et al., 1994).


Star spread

We first compute, for every protein v in a chosen species, every neighbor connected to v by an edge with weight greater than a threshold; this is the star, S v of the protein (Fig. 1a). We greedily order the proteins v by the total weight of S v and for each find the subset S * v ⊂ S v such that S * v is a highly weighted neighborhood of v (Fig. 1b). This is done using a spectral local graph partitioning algorithm with approximate Personalized PageRank vectors, similar to the PageRank-Nibble algorithm. The resulting S * v represents a functionally conserved interaction cluster, a set of networkaligned proteins. This is repeated for every protein in all species not already assigned to an S * v , yielding assignments for all vertices. While it is not clear exactly how the order of vertex choice affects the results, this ordering performs better empirically than others we have tried, including random ordering. The ordering of species is discussed below.  Fig. 1. An example of star spread on the five known eukaryotic networks. (a) S YDR001C , the set of all neighbors of YDR001C with a similarity bounded by a threshold β = 0.01. The illustration emphasizes the key idea of star spread, that the neighborhood of a single protein, YDR001C, has many high-weight neighbors in other networks, each of which are connected to others with varying weights. As the data are noisy, we seek a highly weighted subset of this neighborhood, as opposed to a clique. (b) The shaded area is the resulting conserved interaction cluster S * YDR001C , containing YDR001C, as generated by our local graph partition algorithm.


Spectral partitioning

The main algorithmic challenge in obtaining functionally conserved interaction clusters S * v is uncertainty introduced by the incomplete and inaccurate PPI network data. Thus instead of finding a maximally weighted clique containing v, we find a low-conductance set containing v.

The conductance, (S), of a subset S of a graph G is the ratio of the size of the edge cut to separate S to the number of edges in the larger of the two remaining sets, providing a very natural measure of 'clusterness' of a subset of vertices. Formally, (S) = σ (S)
min{vol(S),2m−vol(S)} , where σ (S) =|{(v x ,v y );v x ∈ S,v y / ∈ S}|, vol(S) = i deg(v i )
, and m is the number of edges in G. Anderson et al. (2006) showed that a low-conductance set containing v can be computed efficiently via the personalized PageRank vector of v. A personalized PageRank vector Pr(γ,v) is the stationary distribution of the random walk on S v in which at every step, with probability γ , the walk 'teleports' back to v and otherwise performs a lazy random walk with transition probabilities proportional to R, the vector of pairwise interaction scores (i.e. with probability 1/2, the walk does not move). Thus in this case, a personalized PageRank vector is the unique solution to:
Pr(γ,v) = γ χ v +(1−γ )Pr(γ,v)W ,(1)
where γ ∈ (0,1], χ v (x) = δ x,v is the indicator vector of v, W = 1 2 (I +D −1 R) is the lazy random walk transition matrix and D is the diagonal of column sums of R. For the purposes of this article, we instead use an efficient approximation p :≈ Pr(γ,v), the details of which can be found in (Anderson et al., 2006).

To compute the minimal conductance cut, we consider the sets T
p j = v i p(v i ) k R ik ≥ p(v j ) k R jk
, or those vertices which contain at least as much of the mass of p, normalized by R. As in (Anderson et al., 2006), we then find the set S * v as:
S * v = min j T p j .(2)

Star merging

While highly efficient, the star spread method has the limitation of not assigning other members of the original network to the neighborhood S v , and so S * v by necessity does not contain any other proteins in the same network as v, even if it is appropriate to do so. To get around this, we introduce a procedure for merging stars, by looking at the neighbors of the neighbors of v. For two stars, S * v 1 and S * v 2 , where v 1 and v 2 are in the same PPI network, if every member of S * v 1 \{v 1 } has v 2 as a neighbor and vice versa, we merge S * v 1 and S * v 2 .


The IsoRankN algorithm

Given k PPI networks G 1 ,G 2 ,...,G k , and a threshold β, IsoRankN proceeds as follows:

(1) Run the original IsoRank on every pair of networks to obtain scores R ij on all edges of the functional similarity graph.

(2) For every protein v, compute the star
S v = v j ∈ N(v)|w(v,v j ) ≥ βmax j w(v,v j ) , where N(v)
is the neighborhood of v in the functional similarity graph.

(3) Pick an arbitrary remaining PPI network G and order the proteins v ∈ G by the sum of edge weights in the induced graph on S v . In order, excluding proteins already assigned to clusters, spectrally partition S v to obtain S * v . (4) Merge every pair of clusters S * v 1 and S
* v 2 in which ∀v i ∈ S * v 2 \{v 2 },w(v 1 ,v i ) ≥ βmax j w(v 1 ,v j ) and ∀v j ∈ S * v 1 \{v 1 },w(v 2 ,v j ) ≥ βmax j w(v 2 ,v j ) .
(5) Repeat steps 3 and 4 until all proteins are assigned to a cluster.